<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- <script type="text/javascript" src="https://livejs.com/live.js"></script> -->
  <script type="text/javascript" src="js/js_func.js"></script>
  <title>Rajit Rajpal</title>

  <meta name="author" content="Rajit Rajpal">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Rajit's personal website, mingling encouraged!">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/rajit.jpg">
</head>
<body>
<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
<tr style="padding:0px">
  <td style="padding:0px">
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:2.5%;width:63%;vertical-align:middle">
        <p style="text-align:center">
          <name>Rajit Rajpal</name>
        </p>
        <p>I recently graduated with a B.A. in Data Science with a domain emphasis in Applied Mathematics from UC Berkeley. I am currently pursuing an MSc in Computational Applied Mathematics at the University of Edinburgh. In between these degrees, I worked as a Data Scientist at Rhombus Power, NASA Research Park, solving problems for the US Air Force.
        </p>
        <p style="text-align:center">
          <a href="mailto:rajpal106@berkeley.edu">Email</a> &nbsp/&nbsp
          <a href="https://github.com/rajit906">Github</a> &nbsp/&nbsp
          <!-- <a href="files/Jacob Yeung CV.pdf">CV</a> &nbsp/&nbsp -->
          <a href="https://www.linkedin.com/in/rajit-rajpal/">LinkedIn</a>
        </p>
      </td>
      <td style="padding:2.5%;width:30%;max-width:30%">
        <a href="images/rajit.jpg"><img style="width:95%;max-width:95%;border-radius:50%;" alt="profile photo" src="images/rajit.jpg" class="hoverZoomLink"></a>
      </td>
    </tr>
    </tbody></table>

    <!-- Research -->
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <heading>Research</heading>

      </td>
    </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
      <td style="padding:20px;width:20%;vertical-align:middle">
        <!-- <img src='images/hangul_fonts.png' width="100%"> -->
        <a href="images/2od.gif"><img src="images/2od.gif"  width="100%" class="thumbnail" alt="hangul fonts photo"></a>
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle">
        <papertitle>Adaptively tuned preconditioner for Hamiltonian Monte Carlo using Local Langevin Ensembles</papertitle>
        <br>
        <strong>Rajit Rajpal</strong>,
        Benedict Leimkuhler,
        Peter Whalley
        <br>
        <em>June 2023 - Present</em>
        <br>
        <a href="javascript:toggleblock('hangul fonts')">description</a> /

        <p align="justify"> <i id="hangul fonts">
          We develop a rigorous statistical methodology and a highly parallelizable algorithm for improving the efficiency of HMC which allows it to sample from distributions with curved correlation structure and moderate energy barriers.</i></p>
        <p></p>
      </td>
    </tr>

      <tr>
      <td style="padding:20px;width:40%;vertical-align:middle">
        <!-- <img src='images/hangul_fonts.png' width="100%"> -->
        <a href="images/neural_ode.png"><img src="images/neural_ode.png"  width="100%" class="thumbnail" alt="hangul fonts photo"></a>
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle">
        <papertitle>Interpolating coarse-grained data of physical systems with Neural ODE</papertitle>
        <br>
        Junyi Guo,
        <strong>Rajit Rajpal</strong>
        <br>
        Dec 2022
        <br>
        <a href="javascript:toggleblock('hangul fonts')">description</a> /
        <a href="https://github.com/rajit906/rajit906.github.io/blob/main/neuralODE_poster.pdf">poster</a> /

        <p align="justify"> <i id="hangul fonts">
          We leverage a Runge-Kutta-4 solver in an autoencoder architecture to interpolate the dynamics of physical systems such as the pendulum and 2D-vorticity data. Supervisor: Ben Erichson.</i></p>
        <p></p>
      </td>
    </tr>

      <tr>
      <td style="padding:20px;width:40%;vertical-align:middle">
        <!-- <img src='images/hangul_fonts.png' width="100%"> -->
        <a href="images/lksvd.png"><img src="images/lksvd.png"  width="100%" class="thumbnail" alt="hangul fonts photo"></a>
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle">
        <papertitle>Dictionary Learning and inference with Langevin Dynamics</papertitle>
        <br>
        <strong>Rajit Rajpal</strong>,
        Daniel Abraham
        <br>
        <em>Dec 2021</em>
        <br>
        <a href="javascript:toggleblock('hangul fonts')">description</a> /
        <a href="https://github.com/rajit906/rajit906.github.io/blob/main/Sparse_Coding_Inference_Poster.pdf">poster</a> /

        <p align="justify"> <i id="hangul fonts">
          We improve upon the alternating minimization scheme for learning and inference in Sparse Coding by inferring the distribution using Langevin Dynamics with a spike-and-slab prior rather than just the MAP estimate with a Laplace prior. Supervisor: Bruno Olshausen.</i></p>
        <p></p>
      </td>
    </tr>

    <!-- Projects -->
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <heading>Projects</heading>

      </td>
    </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle">
        <!-- <img src='images/hangul_fonts.png' width="100%"> -->
        <a href="images/gp_rejection_sample005.png"><img src="images/gp_rejection_sample005.png"  width="100%" class="thumbnail" alt="hangul fonts photo"></a>
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle">
        <papertitle>Eigenstructure of Neural Network Gaussian Processes</papertitle>
        <br>
        <em>In Progress</em>
        <br>
        <a href="javascript:toggleblock('hangul fonts')">description</a> /
        <p align="justify"> <i id="hangul fonts">
          This is my personal endeavour to view the popular infinite width Neural Networks Gaussian Processes. The idea is that since a Gaussian Process can be expressed as an infinite sum of eigenvalues and eigenfunctions with random coefficients by the Karhunen-Loeve expansion, which we can use to simulate this Gaussian Random Field. The equation to solve for these eigenfunctions and eigenvalues can be expressed as a Fredholm Integral Equation. Unfortunately, it is very difficult to solve this analytically. A popular numerical method is the Nystrom method. This is the exact interpretation of PCA. </i></p>
        <p></p>
      </td>
    </tr>
      
    </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle">
        <!-- <img src='images/hangul_fonts.png' width="100%"> -->
        <a href="images/baoab.png"><img src="images/baoab.png"  width="100%" class="thumbnail" alt="hangul fonts photo"></a>
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle">
        <papertitle>Studying Discretizations of Langevin Dynamics</papertitle>
        <br>
        <em>2023</em>
        <br>
        <a href="https://github.com/rajit906/Discretizations-of-Langevin-Dynamics/blob/main/Langevin_Discretizations.ipynb">website</a> /
        <a href="javascript:toggleblock('hangul fonts')">description</a> /
        <p align="justify"> <i id="hangul fonts">
          As part of MATH 11197, the project was to analyze the BAOAB and UBU discretizations of Langevin Dynamics on simple 1D-potentials. </i></p>
        <p></p>
      </td>
    </tr>

      </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle">
        <!-- <img src='images/hangul_fonts.png' width="100%"> -->
        <a href="images/lyapunov.png"><img src="images/lyapunov.png"  width="100%" class="thumbnail" alt="hangul fonts photo"></a>
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle">
        <papertitle>Estimating Lyapunov Exponents of Product of Large Random Matrices</papertitle>
        <br>
        <em>2023</em>
        <br>
        <a href="https://github.com/rajit906/lyapunov_matrix_product/blob/main/lyapunov.ipynb">website</a> /
        <a href="javascript:toggleblock('hangul fonts')">description</a> /
        <p align="justify"> <i id="hangul fonts">
          As part of MATH 10098, I implemented a simpler form of Jacques Venneste's generalised algorithm to estimate the Lyapunov Exponent of Products of Large Random Matrices. </i></p>
        <p></p>
      </td>
    </tr>
      
    </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle">
        <!-- <img src='images/hangul_fonts.png' width="100%"> -->
        <a href="images/eoc.png"><img src="images/eoc.png"  width="100%" class="thumbnail" alt="hangul fonts photo"></a>
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle">
        <papertitle>Neural Networks thrive at the Edge of Chaos!</papertitle>
        <br>
        <em>2023</em>
        <br>
        <a href="https://github.com/rajit906/edge_of_chaos/blob/main/Rajit_Poster_EoC_A1.pdf">website</a> /
        <a href="javascript:toggleblock('hangul fonts')">description</a> /
        <p align="justify"> <i id="hangul fonts">
          Poster Presentation to summarize work done in a particular area of a field. I chose the Edge of Chaos concept in Deep Learning and how Neural Networks perform optimally at this boundary. It is primarily an excerpt from Ling Feng's work.
        <p></p>
      </td>
        
      </td>
    </tr>
      
    </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle">
        <!-- <img src='images/hangul_fonts.png' width="100%"> -->
        <a href="images/twin_pendulum.png"><img src="images/twin_pendulum.png"  width="100%" class="thumbnail" alt="hangul fonts photo"></a>
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle">
        <papertitle>Simulating Hamiltonian Dynamics</papertitle>
        <br>
        <em>2023</em>
        <br>
        <a href="https://github.com/rajit906/Simulating-Hamiltonian-Dynamics/tree/main">website</a> /
        <a href="javascript:toggleblock('hangul fonts')">description</a> /
        <p align="justify"> <i id="hangul fonts">
          Simulated Hamiltonian Dynamics on the Lennard-Jones Trimer model and the Twin Pendulum using the Leapfrog integrator. </i></p>
        <p></p>
      </td>
        
      </td>
    </tr>

    </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle">
        <!-- <img src='images/hangul_fonts.png' width="100%"> -->
        <a href="images/lebesgue.png"><img src="images/lebesgue.png"  width="100%" class="thumbnail" alt="hangul fonts photo"></a>
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle">
        <papertitle>Measure Theory Presentation</papertitle>
        <br>
        <em>April 2021</em>
        <br>
        <a href="https://github.com/rajit906/Lebesgue-Measure/blob/main/Lebesgue_Measure%20(1).pdf">website</a> /
        <a href="https://drive.google.com/file/d/1-ckfY9H1QOPXwH6zNpQFX9Gp4-JFTeY_/view?usp=sharing">video</a> /
        <a href="javascript:toggleblock('hangul fonts')">description</a> /
        <p align="justify"> <i id="hangul fonts">
          Lebesgue Measure notes based on a lecture-style group presentation I gave to MATH 104: Real Analysis in Spring 2021. </i></p>
        <p></p>
      </td>
        
      </td>
    </tr>

      <tr>
      <td style="padding:20px;width:40%;vertical-align:middle">
        <!-- <img src='images/hangul_fonts.png' width="100%"> -->
        <a href="images/deepfake.png"><img src="images/deepfake.png"  width="100%" class="thumbnail" alt="hangul fonts photo"></a>
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle">
        <papertitle>Detecting Deepfakes using a hybrid CNN-LSTM</papertitle>
        <br>
        Arth Vidyarthi,
        Kobe Oh,
        James Dai,
        Vijay Singh,
        <strong>Rajit Rajpal</strong>,
        <br>
        <em>Internship project</em>, Aug 2020
        <br>
        <a href="javascript:toggleblock('hangul fonts')">description</a> /
        <a href="https://www.fakenetai.com">website</a> /
        <p align="justify"> <i id="hangul fonts">
          I was part of a team of 5 that surpassed 80% Top-1 accuracy on Facebookâ€™s Deep Fake Detection Challenge dataset by creating hybrid CNN-LSTM models and implementing transfer learning research papers in PyTorch. We launched a service based on it.</i></p>
        <p></p>
      </td>
    </tr>

      
      
    <!-- Teaching -->
    <table class="center">
      <tr>
        <td>
          <heading>Teaching</heading>
        </td>
      </tr>
      <tr>
        <td width="75%" valign="center">
          <p>
          <p style="font-size:18px">I have been a teaching assistant for the following course:</p>
          <ul>
            <li><a href="https://math.berkeley.edu/~apaulin/54%20(Spring%202022).html/">
                <papertitle>Linear Algebra and Differential Equations (MATH 54) - Summer 2021, Fall 2021, Spring 2022 - David Nadler, Alexander Paulin</papertitle>
              </a></li>
          </ul>
          <ul>
            <li><a href="https://classes.berkeley.edu/content/2020-spring-stat-89a-001-lec-001/">
                <papertitle>Linear Algebra for Data Science (STAT 89A) - Spring 2021 - Michael Mahoney, Ben Erichson</papertitle>
              </a></li>
          </ul>
          </p>
        </td>
      </tr>
    </table>


    <!-- Education -->
    <table class="left"><tbody>
      <tr>
        <td>
          <heading>Experience</heading>
        </td>
      </tr>
      </tbody></table>
      <table width="70%" align="left" border="0" cellpadding="10"><tbody>
      <tr>
        <td style="padding-left:20px;padding-right:20px;width:35%;vertical-align:middle"><img src="images/ucb.png", width="60%", alt="berkeley logo"></td>
        <td width="80%" valign="center" >
          <b>University of California, Berkeley</b>
          <br> Aug 2019 - May 2022
          <br>
          <br> <b>B.A. Data Science (Domain Emphasis: Applied Mathematics)</b>
        </td>
      </tr>
      <tr>
        <td style="padding-left:20px;padding-right:20px;width:35%;vertical-align:middle"><img src="images/nasa.jpg", width="60%", alt="nasa logo"></td>
        <td width="80%" valign="center" >
          <b>NASA Ames Research Center - Rhombus Power</b>
          <br> March 2022 - March 2023
          <br>
          <br> <b>Data Scientist</b>
        </td>
      </tr>
      <tr>
        <td style="padding-left:20px;padding-right:20px;width:35%;vertical-align:middle"><img src="images/edinburgh.png", width="60%", alt="edinburgh logo"></td>
        <td width="80%" valign="center" >
          <b>University of Edinburgh</b>
          <br> Aug 2023 - Aug 2024
          <br>
          <br> <b>MSc in Computational Applied Mathematics</b>
        </td>
      </tr>  
      </tbody></table>



    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
      <td style="padding:0px">
        <br>
        <p style="text-align:right;font-size:small;">
          <a href="https://github.com/jonbarron/website">Cloned from here!</a>
          <br> Last updated: May 23, 2023
        </p>
      </td>
    </tr>
    </tbody></table>
  </td>
</tr>
</table>

<!-- <script xml:space="preserve" language="JavaScript">
hideblock('edca');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('animal reid');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('hangul fonts');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('convolution pruning');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('deepchrome 2.0');
</script> -->

</body>

</html>
